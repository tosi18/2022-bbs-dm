{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/w4bo/2022-bbs-dm/blob/main/notebooks/05-BreastCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ae0f114b-aa26-5802-345f-83fd12c570fe",
        "id": "KV6MsSY3NhMX"
      },
      "source": [
        "# Breast cancer\n",
        "\n",
        "Classify the Stage of Breast Cancer M (Malignant) and B (Bengin).\n",
        "\n",
        "Goal: achieve the highest accuracy.\n",
        "\n",
        "You are free to use any method/model from sklearn and pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e3200e6e-62d4-1d74-496b-c5197a574dcb",
        "id": "joeq722kNhMb"
      },
      "outputs": [],
      "source": [
        "# Import the libraries used for machine learning\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
        "import seaborn as sns # used for plot interactive graph. I like it most for plot\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
        "from sklearn.model_selection import KFold # use for cross validation\n",
        "from sklearn.model_selection import GridSearchCV # for tuning parameter\n",
        "from sklearn.ensemble import RandomForestClassifier # for random forest classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics # for the check the error and accuracy of the model\n",
        "import random\n",
        "import os\n",
        "\n",
        "# SEED all random generators\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# read the data\n",
        "df = pd.read_csv(\"datasets/breastcancer.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70XlP2DnNhMf"
      },
      "source": [
        "## Data understanding\n",
        "\n",
        "Hints\n",
        "\n",
        "- There are 569 observations with 30 features each\n",
        "- Each observation is labelled with a `diagnosis`\n",
        "\n",
        "Take a first glance to the dataset\n",
        "\n",
        "- Are there null values?\n",
        "- Which are the attribute types?\n",
        "- Which are the attribute ranges?\n",
        "- How many labels?\n",
        "- Are classes unbalanced?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7036d299-0057-db0a-d892-fe212c0d612c",
        "id": "gjm_MQO5NhMg"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1109ea03-5b73-25fa-72ca-6695de4b0c5b",
        "id": "oECwLtSFNhMh"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Z6_DHONhMh"
      },
      "source": [
        "### Feature semantics\n",
        "\n",
        "Hint:\n",
        "- id of the observation (observation != cell)\n",
        "- diagnosis (M = malignant, B = benign)\n",
        "- Ten real-valued features are computed for each cell nucleus:\n",
        "    - radius (mean of distances from center to points on the perimeter)\n",
        "    - texture (standard deviation of gray-scale values)\n",
        "    - perimeter\n",
        "    - area\n",
        "    - smoothness (local variation in radius lengths)\n",
        "    - compactness (perimeter^2 / area - 1.0)\n",
        "    - concavity (severity of concave portions of the contour)\n",
        "    - concave points (number of concave portions of the contour)\n",
        "    - symmetry\n",
        "    - fractal dimension (\"coastline approximation\" - 1)\n",
        "\n",
        "`*_mean`: the means of all cells\n",
        "\n",
        "`*_se`: standard error of all cells\n",
        "\n",
        "`*_worst`: the worst cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "jeYgvVYINhMi"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4L60PLNNhMj"
      },
      "outputs": [],
      "source": [
        "df['diagnosis'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31FKjH82NhMl"
      },
      "outputs": [],
      "source": [
        "df['diagnosis'].value_counts().plot(kind=\"bar\", label=\"Count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhQRBxa8NhMm"
      },
      "outputs": [],
      "source": [
        "sns.countplot(df['diagnosis'], label=\"Count\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZTHUVMlNhMm"
      },
      "source": [
        "### Summing up\n",
        "\n",
        "| Question | Answer | Do we need action? |\n",
        "| -        | -      | - |\n",
        "| Are there null values? | Yes | No need for imputation, drop the column |\n",
        "| Which are the attribute types? | All attributes are numeric but `diagnosis` | Encode diagnosis | \n",
        "| Which are the attribute ranges? | Attribute ranges are similar | We could apply normalization |\n",
        "| How many labels? | 2 | - |\n",
        "| Are classes unbalanced? | No, classess are almost equally distributed | No rebalancing |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9041739c-1d90-970b-55ec-224ed821898a",
        "id": "c4HCltcuNhMn"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "Drop the unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9ec57be7-c20b-5895-2f20-0f32651b3f79",
        "id": "weH1AP65NhMo"
      },
      "outputs": [],
      "source": [
        "# `Unnamed:32` has 0 non null objects, all values are null. Drop the column\n",
        "df.drop([\"id\", \"Unnamed: 32\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dbdd0bf6-da03-c390-0e7a-f6b181f8e127",
        "id": "SVylZ7yvNhMp"
      },
      "outputs": [],
      "source": [
        "# map the diagnosis column to numeric\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22aaxXUkNhMq"
      },
      "source": [
        "### Data visualization\n",
        "\n",
        "- Check the attribute's distribution\n",
        "- Check the relationships between attributes (e.g., the correlation). Should we keep all attributes?\n",
        "\n",
        "For now, let's just focus on `*_mean` attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68f07b98-c05a-f3e6-7dbe-8e39ab7d13f6",
        "id": "LiVPTPcvNhMr"
      },
      "outputs": [],
      "source": [
        "# Data can be divided into three parts (i.e., families of columns)\n",
        "features_mean = list(df.columns[1:11]) + [\"diagnosis\"]\n",
        "features_se = list(df.columns[11:20]) + [\"diagnosis\"]\n",
        "features_worst = list(df.columns[21:31]) + [\"diagnosis\"]\n",
        "print(\"features_mean: \" + str(features_mean))\n",
        "print(\"features_se: \" + str(features_se))\n",
        "print(\"features_worst: \" + str(features_worst))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLKpUcTDNhMs"
      },
      "outputs": [],
      "source": [
        "df[features_mean].hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZheqKQjNhMs"
      },
      "outputs": [],
      "source": [
        "g = sns.pairplot(df[features_mean], hue='diagnosis', markers='+')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjQ9aui4NhMs"
      },
      "outputs": [],
      "source": [
        "# df[features_se].hist(bins=50, figsize=(20,15))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUnjf5AZNhMt"
      },
      "outputs": [],
      "source": [
        "# g = sns.pairplot(df[features_se], hue='diagnosis', markers='+')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwX5m2EvNhMu"
      },
      "outputs": [],
      "source": [
        "#  df[features_worst].hist(bins=50, figsize=(20,15))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LBeqaAslNhMv"
      },
      "outputs": [],
      "source": [
        "# g = sns.pairplot(df[features_worst], hue='diagnosis', markers='+')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "5wREKdQLNhMv"
      },
      "outputs": [],
      "source": [
        "df = df[features_mean]\n",
        "from scipy.stats import pearsonr\n",
        "rho = df.corr(method ='pearson')\n",
        "pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
        "p = pval.applymap(lambda x: ''.join(['*' for t in [0.01, 0.05, 0.1] if x <= t]))\n",
        "rho.round(2).astype(str) + p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQGrgHoqNhMw"
      },
      "outputs": [],
      "source": [
        "min_corr = 0.3\n",
        "kot = rho[(abs(rho) >= min_corr) & (rho < 1)]\n",
        "plt.figure(figsize=(14, 14))\n",
        "sns.heatmap(kot, cmap=sns.color_palette(\"coolwarm\", as_cmap=True), annot=True, fmt= '.2f',annot_kws={'size': 15})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fr0T-rWNhMx"
      },
      "source": [
        "### Should we drop some attributes?\n",
        "\n",
        "- `radius_mean`, `perimeter_mean`, and `area_mean` are highly correlated, keep `permiter`\n",
        "- `compactness_mean`, `concavity_mean` and `concavepoint_mean` are highly correlated, keep `compactness_mean`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fcd92fe8-fb89-d377-f135-c053e562e820",
        "id": "W7Ul0U1hNhMx"
      },
      "outputs": [],
      "source": [
        "# now these are the variables that we will use for prediction\n",
        "prediction_var = ['texture_mean', 'perimeter_mean', 'smoothness_mean', 'compactness_mean', 'symmetry_mean']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_OF2Z6PNhMy"
      },
      "source": [
        "## Modeling with scikit-learn\n",
        "\n",
        "Preparing the dataset for the ML pipeline.\n",
        "- X: the dataset\n",
        "- y: the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWGUNwGBNhMy"
      },
      "outputs": [],
      "source": [
        "def set_dataset(feature_list):\n",
        "    X = df[[x for x in feature_list if x != \"diagnosis\"]]\n",
        "    y = df['diagnosis']\n",
        "    # print(X.head())\n",
        "    print(X.shape)\n",
        "    # print(y.head())\n",
        "    print(y.shape)\n",
        "    return X, y\n",
        "\n",
        "X, y = set_dataset(prediction_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okIWN5k8NhMz"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXxI5WVNNhMz"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kjaujs1NhM0"
      },
      "source": [
        "## Split the dataset into a training set and a testing set\n",
        "\n",
        "### Advantages\n",
        "- By splitting the dataset pseudo-randomly into a two separate sets, we can train using one set and test using another.\n",
        "- This ensures that we won't use the same observations in both sets.\n",
        "- More flexible and faster than creating a model using all of the dataset for training.\n",
        "\n",
        "### Disadvantages\n",
        "- The accuracy scores for the testing set can vary depending on what observations are in the set. \n",
        "- This disadvantage can be countered using k-fold cross-validation.\n",
        "\n",
        "### Notes\n",
        "- The accuracy score of the models depends on the observations in the testing set, which is determined by the seed of the pseudo-random number generator (random_state parameter).\n",
        "- As a model's complexity increases, the training accuracy (accuracy you get when you train and test the model on the same data) increases.\n",
        "- If a model is too complex or not complex enough, the testing accuracy is lower.\n",
        "- For KNN models, the value of k determines the level of complexity. A lower value of k means that the model is more complex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da2eaf5c-6f86-b320-a591-fb7b7e0fb12c",
        "id": "T7oBPXabNhM1"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=round(len(df.index) / 5))\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MELx2M9MNhM1"
      },
      "source": [
        "Fit your model and try it with several parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-czONyQNhM1"
      },
      "outputs": [],
      "source": [
        "def fit_knn(X_train, y_train, X_test, y_test):\n",
        "    # experimenting with different k values\n",
        "    k_range = list(range(1, 30))\n",
        "    scores = []\n",
        "    for k in k_range:\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_test)\n",
        "        scores.append(metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "    plt.plot(k_range, scores)\n",
        "    plt.xticks(k_range)\n",
        "    plt.xlabel('Value of k for KNN')\n",
        "    plt.ylabel('Accuracy Score')\n",
        "    plt.title('k-Nearest-Neighbors')\n",
        "    plt.show()\n",
        "\n",
        "fit_knn(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA3OBSffNhM2"
      },
      "source": [
        "What if I compare the model vs the model trained on the training set only?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcfII3niNhM2"
      },
      "outputs": [],
      "source": [
        "fit_knn(X_train, y_train, X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUqv8FQQNhM2"
      },
      "source": [
        "What if I choose a more complex model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4936a3a9-e7fd-81a1-1aec-a267224569d5",
        "scrolled": true,
        "id": "EqgQaxNCNhM2"
      },
      "outputs": [],
      "source": [
        "def fit_forest(X_train, y_train, X_test, y_test):\n",
        "    model=RandomForestClassifier(n_estimators=100) # a simple random forest model\n",
        "    model.fit(X_train, y_train) # now fit our model for training data\n",
        "    y_pred = model.predict(X_test) # predict for the test data\n",
        "    # prediction will contain the predicted value by our model predicted values of dignosis column for test inputs\n",
        "    print(\"Accuracy: \" + str(metrics.accuracy_score(y_pred, y_test))) # to check the accuracy\n",
        "    # here we will use accuracy measurement between our predicted value and our test output values\n",
        "    featimp = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "    print(\"\\nFeatures sorted by descending importance:\")\n",
        "    print(featimp) # this is the property of Random Forest classifier that it provide us the importance of the features used\n",
        "\n",
        "fit_forest(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "87950903-844c-058d-23d5-2d55ae58de75",
        "id": "hUUlzoJPNhM3"
      },
      "source": [
        "Now lets do this for all `feature_mean` so that from Random forest we can get the feature which are important"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "20b8aaf5-677c-a2af-c998-dfd5fa713115",
        "id": "RMBW1xZ7NhM3"
      },
      "outputs": [],
      "source": [
        "X, y = set_dataset(features_mean) # taking all features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
        "fit_forest(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3Lmpx8FNhM3"
      },
      "outputs": [],
      "source": [
        "fit_knn(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyfkM0LdNhM4"
      },
      "source": [
        "What if we use cross-validation?\n",
        "\n",
        "https://scikit-learn.org/stable/modules/cross_validation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAPLKqtgNhM4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def cv(model, X, y):\n",
        "    scores = cross_val_score(model, X, y, cv=5)\n",
        "    print(\"Scores: \" + str(scores))\n",
        "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "cv(model, X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecBBg7FjNhM4"
      },
      "outputs": [],
      "source": [
        "model = KNeighborsClassifier(n_neighbors=10)\n",
        "cv(model, X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdXIv7YONhM5"
      },
      "source": [
        "Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjCpvBa5NhM6"
      },
      "outputs": [],
      "source": [
        "# lets Make a function for Grid Search CV\n",
        "def gridsearch_cv(model,param_grid, X_train, y_train):\n",
        "    clf = GridSearchCV(model, param_grid, cv=5, scoring=\"accuracy\", verbose=1, n_jobs=2)\n",
        "    clf.fit(X_train, y_train)\n",
        "    print(\"The best parameters are:\")\n",
        "    print(clf.best_params_)\n",
        "    print(\"The best estimator is \" + str(clf.best_estimator_))\n",
        "    print(\"The best score is \" + str(clf.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f5238051-7292-5a2a-f255-cd68c9797125",
        "id": "WORu1WCJNhM6"
      },
      "outputs": [],
      "source": [
        "model = KNeighborsClassifier()\n",
        "\n",
        "k_range = list(range(1, 30, 3))\n",
        "leaf_size = list(range(1, 30, 3))\n",
        "param_grid = {'n_neighbors': k_range, 'leaf_size': leaf_size} #, 'weights': ['uniform', 'distance']}\n",
        "\n",
        "gridsearch_cv(model, param_grid, X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fff56e83-608f-bee1-8cdf-d75b07cab36a",
        "id": "4yKnTyHmNhM7"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "estimator_range = [10, 50, 100]\n",
        "param_grid = {'n_estimators': estimator_range}\n",
        "\n",
        "gridsearch_cv(model, param_grid, X, y)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "name": "05-BreastCancer.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}